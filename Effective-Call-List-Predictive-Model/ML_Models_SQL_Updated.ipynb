{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TYOujBIAOGG3"
   },
   "outputs": [],
   "source": [
    "import google.cloud.bigquery as bq\n",
    "import pandas_gbq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waPIpOIgOGG6"
   },
   "outputs": [],
   "source": [
    "project_id = '.................'\n",
    "df = pd.read_gbq(\"\"\"with call_list as (\n",
    "\t(\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tad_hoc.store_conversions\n",
    "\t\twhere\n",
    "\t\t\tconverted = 1\n",
    "\t\torder by rand()\n",
    "\t\tlimit 358\n",
    "\t)\n",
    "\tunion all\n",
    "\t(\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tad_hoc.store_conversions\n",
    "\t\twhere\n",
    "\t\t\tconverted = 0\n",
    "\t\torder by rand()\n",
    "\t\tlimit 358\n",
    "\t)\n",
    "),\n",
    "live_ads as (\n",
    "\tselect\n",
    "\t\tcase\n",
    "\t\t\twhen ac_store_id.ad_id is not null then cast(ac_store_id.value as int64)\n",
    "\t\t\telse ads.store_id\n",
    "\t\t\tend as store_id,\n",
    "\t\taa.date,\n",
    "\t\tcount(*) live_ads,\n",
    "\t\tsum(\n",
    "\t\t\tcase\n",
    "\t\t\t\twhen case when ac_type.ad_id is not null then ac_type.value else ads.type end in ('let', 'rent') then coalesce(\n",
    "\t\t\t\t\tcase\n",
    "\t\t\t\t\t\twhen ac_monthly_rent.ad_id is not null then cast(ac_monthly_rent.value as int64)\n",
    "\t\t\t\t\t\telse cast(ap_monthly_rent.value as int64)\n",
    "\t\t\t\t\t\tend,\n",
    "\t\t\t\t\tcase\n",
    "\t\t\t\t\t\twhen ac_max_rent.ad_id is not null then cast(ac_max_rent.value as int64)\n",
    "\t\t\t\t\t\telse cast(ap_max_rent.value as int64)\n",
    "\t\t\t\t\t\tend,\n",
    "\t\t\t\t\tcase\n",
    "\t\t\t\t\t\twhen ac_rental.ad_id is not null then cast(ac_rental.value as int64)\n",
    "\t\t\t\t\t\telse cast(ap_rental.value as int64)\n",
    "\t\t\t\t\t\tend\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\telse\n",
    "\t\t\t\t\tcase\n",
    "\t\t\t\t\t\twhen ac_price.ad_id is not null then cast(ac_price.value as int64)\n",
    "\t\t\t\t\t\telse ads.price\n",
    "\t\t\t\t\t\tend\n",
    "\t\t\t\tend\n",
    "\t\t\t)/count(*) as avg_price_per_live_ad\n",
    "\tfrom\n",
    "\t\tblocket_tf.active_ads aa\n",
    "\tjoin blocket.ads ads using (ad_id)\n",
    "\tleft join blocket_tf.ad_changes ac_store_id on\n",
    "\t\tac_store_id.ad_id = aa.ad_id\n",
    "\t\tand ac_store_id.column_name = 'store_id'\n",
    "\t\tand not ac_store_id.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_store_id.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_store_id.end_time\n",
    "\tleft join blocket_tf.ad_changes ac_price on\n",
    "\t\tac_price.ad_id = aa.ad_id\n",
    "\t\tand ac_price.column_name = 'price'\n",
    "\t\tand not ac_price.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_price.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_price.end_time\n",
    "\tleft join blocket_tf.ad_changes ac_type on\n",
    "\t\tac_type.ad_id = aa.ad_id\n",
    "\t\tand ac_type.column_name = 'type'\n",
    "\t\tand not ac_type.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_type.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_type.end_time\n",
    "\tleft join blocket.ad_params ap_monthly_rent on\n",
    "\t\tap_monthly_rent.ad_id = aa.ad_id\n",
    "\t\tand ap_monthly_rent.name = 'monthly_rent'\n",
    "\tleft join blocket_tf.ad_changes ac_monthly_rent on\n",
    "\t\tac_monthly_rent.ad_id = aa.ad_id\n",
    "\t\tand ac_monthly_rent.column_name = 'monthly_rent'\n",
    "\t\tand ac_monthly_rent.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_monthly_rent.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_monthly_rent.end_time\n",
    "\tleft join blocket.ad_params ap_max_rent on\n",
    "\t\tap_max_rent.ad_id = aa.ad_id\n",
    "\t\tand ap_max_rent.name = 'max_rent'\n",
    "\tleft join blocket_tf.ad_changes ac_max_rent on\n",
    "\t\tac_max_rent.ad_id = aa.ad_id\n",
    "\t\tand ac_max_rent.column_name = 'max_rent'\n",
    "\t\tand ac_max_rent.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_max_rent.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_max_rent.end_time\n",
    "\tleft join blocket.ad_params ap_rental on\n",
    "\t\tap_rental.ad_id = aa.ad_id\n",
    "\t\tand ap_rental.name = 'rental'\n",
    "\tleft join blocket_tf.ad_changes ac_rental on\n",
    "\t\tac_rental.ad_id = aa.ad_id\n",
    "\t\tand ac_rental.column_name = 'rental'\n",
    "\t\tand ac_rental.is_param\n",
    "\t\tand cast(aa.date + 1 as timestamp) >= ac_rental.start_time\n",
    "\t\tand cast(aa.date + 1 as timestamp) < ac_rental.end_time\n",
    "\tgroup by 1,2\n",
    "\thaving store_id is not null\n",
    "),\n",
    "credit_balance as (\n",
    "\tselect distinct\n",
    "\t\tstore_id,\n",
    "\t\tdate,\n",
    "\t\tsum(coalesce(coin, 0)) over (partition by store_id order by date rows unbounded preceding) as balance\n",
    "\tfrom\n",
    "\t\t(\n",
    "\t\t\tselect\n",
    "\t\t\t\tstore_id,\n",
    "\t\t\t\tdate(timestamp) as date,\n",
    "\t\t\t\tsum(coalesce(coin, 0)) as coin\n",
    "\t\t\tfrom\n",
    "\t\t\t\tvisualization.unutilized_credits\n",
    "\t\t\tgroup by 1,2\n",
    "\t\t)\n",
    ")\n",
    "select\n",
    "\tcl.store_id,\n",
    "\tcl.call_date,\n",
    "\tcast(s.category as string) as store_category,\n",
    "\tcast(s.region as string) as store_region,\n",
    "\tcoalesce(cb.balance, 0) as credit_balance,\n",
    "\tcoalesce(la.live_ads, 0) as live_ads,\n",
    "\tcoalesce(la.avg_price_per_live_ad, 0) as avg_price_per_live_ad,\n",
    "\tsum(case when fd.product = 'paid' then coin else 0 end) as credit_purchased,\n",
    "\tsum(case when fd.product = 'expired' then coin else 0 end) as credit_expired,\n",
    "\tsum(case when fd.product in ('listing', 'prolong') then coin else 0 end) as credit_listing,\n",
    "\tsum(case when fd.product not in ('listing', 'prolong', 'paid', 'expired') then coin else 0 end) as credit_ps,\n",
    "\tcl.converted\n",
    "from\n",
    "\tcall_list cl\n",
    "join blocket.stores s using (store_id)\n",
    "left join live_ads la on\n",
    "\tla.store_id = cl.store_id\n",
    "\tand la.date = cl.call_date - 1\n",
    "left join revenue.fifo_detailed fd on\n",
    "\tfd.store_id = cl.store_id\n",
    "\tand fd.product not in ('void', 'refund_admin', 'compliment', 'transfer_in', 'transfer_out', 'edit')\n",
    "\tand fd.date between cl.call_date - 91 and cl.call_date - 1\n",
    "left join credit_balance cb on\n",
    "\tcb.store_id = cl.store_id\n",
    "\tand cb.date = cl.call_date - 1\n",
    "group by 1,2,3,4,5,6,7, 12\"\"\",              \n",
    "                 project_id = project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbHOy8va0MOM",
    "outputId": "f1ed30c3-c0fb-4653-a45c-13de17eaa9f2"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfpeWVCL36cS"
   },
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OiOfPXi5S0O"
   },
   "outputs": [],
   "source": [
    "df1 =df1.drop('call_date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOfwyGrR5BbH"
   },
   "outputs": [],
   "source": [
    "df1 =df1.drop('store_id',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0n0fIg3u4PR"
   },
   "outputs": [],
   "source": [
    "df1 =df1.drop('store_category',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOcYkoYRu-kG"
   },
   "outputs": [],
   "source": [
    "df1 =df1.drop('store_region',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmSs3Mjtvszx",
    "outputId": "18716ef0-999d-418f-b6a8-8fda77664fcc"
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mKsc6T5OGG7",
    "outputId": "8676a1a3-c376-46e1-e645-28beba891791"
   },
   "outputs": [],
   "source": [
    "(len(df2.loc[df2.converted==1])) / (len(df2.loc[df2.converted == 0])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vDZpjXAOGG8"
   },
   "outputs": [],
   "source": [
    "X = df2.drop('converted', axis=1)\n",
    "y = df2['converted']\n",
    "rus = RandomUnderSampler(random_state=42) \n",
    "#Under-samples the majority classes by randomly picking samples with or without replacement.\n",
    "X_rs, y_rs = rus.fit_resample(X,y) \n",
    "#fit - Finds for the classes statistics before performing sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoefhlF9OGG9"
   },
   "outputs": [],
   "source": [
    "df_rs = pd.DataFrame(np.hstack((X_rs,y_rs[:, None])), columns=df2.columns)\n",
    "df_rs.converted = df_rs.converted.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FflvYUPYOGG9",
    "outputId": "d618ef4d-4818-492c-eebc-67009d2848ef"
   },
   "outputs": [],
   "source": [
    "def naive_predictor(df2): ## gives better accuracy for majority classes\n",
    "    TP = df2.converted.count() - np.sum(df2.converted)\n",
    "    FP = np.sum(df2.converted)\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    recall = TP/(TP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    fscore = (2*precision*recall)/(precision + recall)\n",
    "    print(\"[Accuracy score: {:.4f}, precision: {:.4f}, recall: {:.4f}, f1-score: {:.4f}]\".format(accuracy, precision, recall, fscore))    \n",
    "print('Naive predictor for original dataset:')\n",
    "naive_predictor(df2)\n",
    "print('-'*100)\n",
    "print('Naive predictor for undersampled dataset:')\n",
    "naive_predictor(df_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8peTt5COGG9"
   },
   "outputs": [],
   "source": [
    "# RANDOM UNDERSAMPLING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-dxddh0OGG-"
   },
   "outputs": [],
   "source": [
    "X = df_rs.drop('converted', axis=1)\n",
    "y = df_rs['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1Co8lFmOGG-"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFNz94goOGG-"
   },
   "outputs": [],
   "source": [
    "### CROSS VALIDATION\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"Ridge\": RidgeClassifier(),\n",
    "    \"Stochastic Gradient Boosting\": GradientBoostingClassifier()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7N6zsDRDOGG-",
    "outputId": "b570101d-7a36-47c0-dc62-efc8dfe88bd7"
   },
   "outputs": [],
   "source": [
    "print('Cross-Validation Scores:-')\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(classifier, X_train, y_train, cv=5) \n",
    "    #number of cv you have to try for each selected set of hyperparameters\n",
    "    print('{}: {}'.format(key,round(cv_score.mean()*100.0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QHtj-W7OGG_"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"Logistic Regression\": {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "#     \"Support Vector Classifier\": {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n",
    "    \"Decision Tree\": {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))},\n",
    "    \"KNearest\": {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "    \"Random Forest\": {'n_estimators': [10, 100, 1000],'max_features':['auto', 'sqrt']},\n",
    "    \"MLP\": {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]},\n",
    "    \"Ridge\": {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "    \"Stochastic Gradient Boosting\": {'n_estimators':range(20,81,10),'max_features':['sqrt']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-bnizfgOGG_"
   },
   "outputs": [],
   "source": [
    "def gridsearch(classifier, params):\n",
    "    grid_classifier = GridSearchCV(classifier, params)\n",
    "    grid_classifier.fit(X_train, y_train)\n",
    "    best_classifier = grid_classifier.best_estimator_\n",
    "    return best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R02uT0j2OGG_",
    "outputId": "14785cba-9e61-4a8c-81d2-7d150cb7e7e0"
   },
   "outputs": [],
   "source": [
    "print('Cross-Validation Scores after applying GridSearch -')\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier = gridsearch(classifier,params[key])\n",
    "    cv_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print('{}: {}'.format(key,round(cv_score.mean()*100.0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwZwTYhqOGHA"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    ####Learning curve ####### To check if there's any overfitting\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(name='Training score - Standard Deviation',x=train_sizes,y=train_scores_mean+train_scores_std,\n",
    "                            mode='lines',showlegend=False,marker=dict(color='blue')))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(name='Training score', x=train_sizes, y=train_scores_mean, fill='tonexty',mode='lines+markers',\n",
    "                            marker=dict(color='blue')))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(name='Training score + Standard Deviation', x=train_sizes, y=train_scores_mean-train_scores_std,\n",
    "                            mode='lines', fill='tonexty', showlegend=False,marker=dict(color='blue')))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=train_sizes,y=test_scores_mean+test_scores_std,mode='lines',showlegend=False,\n",
    "                             marker=dict(color='orange')))\n",
    "   \n",
    "    fig.add_trace(go.Scatter(name='Validation Score',x=train_sizes, y=test_scores_mean, mode='lines+markers',fill='tonexty',\n",
    "                            marker=dict(color='orange')))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=train_sizes,y=test_scores_mean-test_scores_std,mode='lines',fill='tonexty',showlegend=False,\n",
    "                            marker=dict(color='orange')))\n",
    "\n",
    "    fig.update_layout(width=700,height=400,template='seaborn',title=title,margin=dict(l=60,r=0,b=0,t=40),legend=dict(orientation='h',x=0.5,y=1),\n",
    "                        xaxis=dict(title='Training examples',mirror=True,linecolor='black',linewidth=2),\n",
    "                        yaxis=dict(title='Scores',range=ylim if ylim is not None else None,\n",
    "                        mirror=True,linecolor='black',linewidth=2))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSPGn7u6OGHB"
   },
   "outputs": [],
   "source": [
    "n_jobs = 10\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "log_reg = gridsearch(LogisticRegression(), params['Logistic Regression'])\n",
    "# svc = gridsearch(SVC(), params['Support Vector Classifier'])\n",
    "decision_tree = gridsearch(DecisionTreeClassifier(), params['Decision Tree'])\n",
    "knearest = gridsearch(KNeighborsClassifier(), params['KNearest'])\n",
    "random_forest = gridsearch(RandomForestClassifier(), params['Random Forest'])\n",
    "MLP = gridsearch(MLPClassifier(),params['MLP'])\n",
    "Ridge = gridsearch(RidgeClassifier(), params['Ridge'])\n",
    "Stochastic_gradient_boosting = gridsearch(GradientBoostingClassifier(), params['Stochastic Gradient Boosting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "GMC-C1iYnYPP",
    "outputId": "604a3df0-55ab-470f-a824-b58554aca68c"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(log_reg,'Logistic Regression', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUN_0uMOOGHB",
    "outputId": "98d9c13b-9faf-464f-e069-238303600144"
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(svc, 'Support Vector Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "lNnLGi7UOGHB",
    "outputId": "94f28ee5-77a4-4fff-ea57-21142216295b"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(decision_tree, 'Decision Tree Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "4a6ZIpfvOGHB",
    "outputId": "4ed1dd18-d472-479e-f7be-874471a6db47"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(knearest, 'KNearest Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "pMM0uuBki6j1",
    "outputId": "f301c81e-7ead-4cb4-fe1d-92966301000a"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(random_forest, 'Random Forest Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "JT44sC7Ki6mp",
    "outputId": "64e971ef-2fe8-450a-dee2-2499e6abb029"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(MLP, 'MLP Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "tC00c_Y_i6qE",
    "outputId": "7f39f379-bc15-4bc1-8cdc-4fc832acdcb5"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(Ridge, 'Ridge Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "5xtR7pq_i6tc",
    "outputId": "6f1b954f-bbfd-45f6-c9e4-223e088eeffb"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(Stochastic_gradient_boosting, 'Stochastic Gradient Boosting Classifier', X_train, y_train, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKNwVztMOGHB"
   },
   "outputs": [],
   "source": [
    "###### KNN AND DT IS CLOSER TO IDEAL CASE ( closer to value '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "oCI06HEAOGHC",
    "outputId": "fdbbbc3f-e6c2-41a8-cc06-8db6f2fa4cad"
   },
   "outputs": [],
   "source": [
    "log_pred = log_reg.predict(X_test)\n",
    "# svc_pred = svc.predict(X_test)\n",
    "tree_pred = decision_tree.predict(X_test)\n",
    "knear_pred = knearest.predict(X_test)\n",
    "rfnear_pred = random_forest.predict(X_test)\n",
    "mlpnear_pred = MLP.predict(X_test)\n",
    "Rnear_pred = Ridge.predict(X_test)\n",
    "SGBnear_pred = Stochastic_gradient_boosting.predict(X_test)\n",
    "\n",
    "log_fpr, log_tpr, log_threshold = roc_curve(y_test, log_pred)\n",
    "# svc_fpr, svc_tpr, svc_threshold = roc_curve(y_test, svc_pred)\n",
    "tree_fpr, tree_tpr, tree_threshold = roc_curve(y_test, tree_pred)\n",
    "knear_fpr, knear_tpr, knear_threshold = roc_curve(y_test, knear_pred)\n",
    "rfnear_fpr, rfnear_tpr, rfnear_threshold = roc_curve(y_test, rfnear_pred)\n",
    "mlpnear_fpr, mlpnear_tpr, mlpnear_threshold = roc_curve(y_test, mlpnear_pred)\n",
    "Rnear_fpr, Rnear_tpr, Rnear_threshold = roc_curve(y_test, Rnear_pred)\n",
    "SGBnear_fpr, SGBnear_tpr, SGBnear_threshold = roc_curve(y_test, SGBnear_pred)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(name='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_test, log_pred)),x=log_fpr,y=log_tpr,mode='lines'))\n",
    "# fig.add_trace(go.Scatter(name='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_test, svc_pred)),x=svc_fpr,y=svc_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_test, tree_pred)),x=tree_fpr,y=tree_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='K-Nearest Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_test, knear_pred)),x=knear_fpr,y=knear_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='Random Forest Classifier Score: {:.4f}'.format(roc_auc_score(y_test, rfnear_pred)),x=rfnear_fpr,y=rfnear_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='MLP Classifier Score: {:.4f}'.format(roc_auc_score(y_test, mlpnear_pred)),x=mlpnear_fpr,y=mlpnear_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='Ridge Classifier Score: {:.4f}'.format(roc_auc_score(y_test, Rnear_pred)),x=Rnear_fpr,y=Rnear_tpr,mode='lines'))\n",
    "fig.add_trace(go.Scatter(name='Stochastic Gradient Classifier Score: {:.4f}'.format(roc_auc_score(y_test, SGBnear_pred)),x=SGBnear_fpr,y=SGBnear_tpr,mode='lines'))\n",
    "\n",
    "fig.add_trace(go.Scatter(name='AUC-ROC=0.5',x=[0,1],y=[0,1],line=dict(dash='dot'),showlegend=False))\n",
    "fig.update_layout(width=1000,height=600,xaxis=dict(mirror=True,linewidth=2,linecolor='black'),yaxis=dict(mirror=True,linewidth=2,linecolor='black'),\n",
    "            title='ROC Curve<br>(All Classifiers)',template='seaborn',legend=dict(x=0.46,y=0,traceorder=\"normal\", font=dict(family=\"sans-serif\",\n",
    "            size=12,color=\"black\"),bgcolor=\"Lightgray\",bordercolor=\"Black\",borderwidth=2),\n",
    "            annotations=[dict(x=0.5,y=0.5,xref=\"x\", yref=\"y\",text=\"Minimum ROC Score of 50% <br>\",showarrow=True,arrowhead=7,ax=40,ay=50)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAwUb1cNOGHC"
   },
   "outputs": [],
   "source": [
    "# From the above curve it can be seen that DT has the highest ROC curve SO, \n",
    "# it is the best model according to this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlxD5qGROGHC",
    "outputId": "c0468032-102d-4de1-beb2-d2ae16a69575"
   },
   "outputs": [],
   "source": [
    "labels = ['Non-Converted', 'Converted']\n",
    "print('#'*125)\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(y_test, log_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "# print('Support Vector Classifier:')\n",
    "# print(classification_report(y_test, svc_pred, target_names=labels))\n",
    "# print('#'*125)\n",
    "print('Decision Tree:')\n",
    "print(classification_report(y_test, tree_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "print('KNearest Neighbours:')\n",
    "print(classification_report(y_test, knear_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "print('Random Forests:')\n",
    "print(classification_report(y_test, rfnear_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "print('MLP:')\n",
    "print(classification_report(y_test, mlpnear_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "print('Ridge:')\n",
    "print(classification_report(y_test, Rnear_pred, target_names=labels))\n",
    "print('#'*125)\n",
    "print('Stochastic Gradient Boosting:')\n",
    "print(classification_report(y_test, SGBnear_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s650_aULOGHH"
   },
   "outputs": [],
   "source": [
    "print('-'*65)\n",
    "print('Ridge Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,Rnear_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, Rnear_pred))\n",
    "print('F1 score:',f1_score(y_test, Rnear_pred))\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('Gradient Boosting Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,SGBnear_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, SGBnear_pred))\n",
    "print('F1 score:',f1_score(y_test, SGBnear_pred))\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('MLP Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,mlpnear_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, mlpnear_pred))\n",
    "print('F1 score:',f1_score(y_test, mlpnear_pred))\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('Decision Tree Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,tree_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, tree_pred))\n",
    "print('F1 score:',f1_score(y_test, tree_pred))\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('K-nearest Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,knear_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, knear_pred))\n",
    "print('F1 score:',f1_score(y_test, knear_pred))\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('Random Forest Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,rfnear_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, rfnear_pred))\n",
    "print('F1 score:',f1_score(y_test, rfnear_pred))\n",
    "print('Recall:',recall_score(y_test, rfnear_pred))\n",
    "print('Precision:',precision_score(y_test, rfnear_pred))\n",
    "\n",
    "print('-'*65)\n",
    "\n",
    "print('-'*65)\n",
    "print('Logistic Regression Classifier')\n",
    "print('-'*65)\n",
    "\n",
    "print('ROC/AUC score:',roc_auc_score(y_test,log_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, log_pred))\n",
    "print('F1 score:',f1_score(y_test, log_pred))\n",
    "print('-'*65)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_Models_SQL_Updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
